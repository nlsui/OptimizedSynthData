from langchain import HuggingFacePipeline, PromptTemplate, LLMChain


class Analyzer:
    def __init__(self, model_pipeline):
        # Set the model pipeline (from main.py)
        self.llm = HuggingFacePipeline(pipeline=model_pipeline)

        # Define the prompt template for analysis
        self.template = """[INST] You are an expert data analyst. Your task is to review a dataset
        containing input-output pairs that are classified based on their nearest neighbor distances.
        Your job is to assess whether the dataset has too much diversity, too little diversity, or whether
        certain datapoints should be removed because they are either too similar (too close) or too far from others.

        For each data point, you will be provided:
        - The input.
        - The output.
        - A classification of whether the point is too close, too far, or within normal range.

        After reviewing the data, write a report that:
        - Recommends whether the dataset has appropriate diversity.
        - Identifies any datapoints that are too similar (too close).
        - Identifies any datapoints that are too far from the others.
        - Suggests if any datapoints should be cut due to these issues.

        Here are the input-output pairs and their classifications:
        {data}

        Please generate your report based on this information. [/INST]"""

        # Set up the PromptTemplate object
        self.prompt = PromptTemplate(template=self.template, input_variables=["data"])

    def analyze(self, below_threshold, above_threshold):
        """
        Analyze the generated data classified based on thresholds and produce a report.

        Parameters:
        - within_threshold: List of dictionaries where nearest neighbor distances are within normal range.
        - below_threshold: List of dictionaries where nearest neighbor distances are below the lower threshold (too close).
        - above_threshold: List of dictionaries where nearest neighbor distances are above the upper threshold (too far).

        Returns:
        - A report generated by the model.
        """

        # Format the data for the analysis prompt, labeling based on thresholds
        data_str = ""

        # Add the data points classified as "too close"
        if below_threshold:
            data_str += "\n### Data Points Too Close (Below Threshold) ###\n"
            data_str += "\n".join([f"Input: {item['text'][0]}\nOutput: {item['text'][1]}\nStatus: Too close to others"
                                   for item in below_threshold])

        # Add the data points classified as "too far"
        if above_threshold:
            data_str += "\n### Data Points Too Far (Above Threshold) ###\n"
            data_str += "\n".join([f"Input: {item['text'][0]}\nOutput: {item['text'][1]}\nStatus: Too far from others"
                                   for item in above_threshold])

        # Create an LLMChain with the model and the prompt
        llm_chain = LLMChain(prompt=self.prompt, llm=self.llm)

        # Generate the report using the formatted data
        report = llm_chain.run({"data": data_str})

        return report
