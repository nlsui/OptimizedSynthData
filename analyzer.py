from langchain import HuggingFacePipeline, PromptTemplate, LLMChain

from data_format import _datapoint_to_string, _parse_generated_pairs, format_string


class Analyzer:
    def __init__(self, model_pipeline):
        # Set the model pipeline (from main.py)
        self.llm = HuggingFacePipeline(pipeline=model_pipeline)

        # Define the prompt template for analysis
        self.adjust_examples_template = """[INST] You are an expert data analyst. Your task is to review a dataset
        containing input-output pairs that were used to generate a new dataset and an evaluation of the results!
        
        Here are the given examples:
        {examples}

        Here are the generated pairs and their classifications:
        {data}

        Based on these results, adjust the examples fo the next generation. Remove examples that might have caused 
        the generation of bad data (should be data that's similar to a bad data-point)
        and replace it with a good classified generated pair.
        The output should be 10 curated input output pairs in this format:
        {format}
        [/INST]"""

        # Set up the PromptTemplate object
        self.adjust_examples_prompt = PromptTemplate(template=self.adjust_examples_template, input_variables=["format", "examples", "data"])

    def analyze(self, below_threshold, above_threshold, within_range, previous_examples):
        """
        Analyze the generated data classified based on thresholds and produce a report.

        Parameters:
        - below_threshold: List of DataPoint objects where nearest neighbor distances are below the lower threshold.
        - above_threshold: List of DataPoint objects where nearest neighbor distances are above the upper threshold.
        - within_range: List of DataPoint objects where nearest neighbor distances are within the normal range.
        - previous_examples: List of previous DataPoint objects for context.

        Returns:
        - A report generated by the model.
        """

        example_str = ""
        data_str = ""

        # Add the data points classified as "too close"
        if below_threshold:
            data_str += "\n### Data Points Too Close To Others ###\n"
            data_str += "\n".join([_datapoint_to_string(item) for item in below_threshold])

        # Add the data points classified as "too far"
        if above_threshold:
            data_str += "\n### Data Points Too Far From All ###\n"
            data_str += "\n".join([_datapoint_to_string(item) for item in above_threshold])

        # Add the data points classified as "in range"
        if within_range:
            data_str += "\n### Data Points Just Right ###\n"
            data_str += "\n".join([_datapoint_to_string(item) for item in within_range])

        # Add the previous examples for context
        if previous_examples:
            example_str += "\n".join([_datapoint_to_string(item) for item in previous_examples])

        # Create an LLMChain with the model and the prompt
        llm_chain = LLMChain(prompt=self.adjust_examples_prompt, llm=self.llm)

        # Generate the report using the formatted data
        report = llm_chain.run({"format": format_string, "examples": example_str, "data": data_str})

        print(report)

        # Parse the report back into DataPoint objects
        parsed_datapoints = _parse_generated_pairs(report)

        return parsed_datapoints
