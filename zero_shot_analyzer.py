from langchain import HuggingFacePipeline, PromptTemplate, LLMChain


class Analyzer:
    def __init__(self, model_pipeline):
        # Set the model pipeline (from main.py)
        self.llm = HuggingFacePipeline(pipeline=model_pipeline)

        # Define the prompt template for analysis
        self.adjust_examples_template = """[INST] You are an expert data synthesis prompt reviewer.
        You are given a data generation prompt as well as 10 data points that were generated using the prompt.
        The datapoints have been labeled, if they are to far away from what the generator should generate,
        to close to other datapoints or just right.
        Your job is to adjust the prompt so that it generates better fitting datapoints!

        Here is the prompt used:
        {prompt}

        Here are the generated pairs and their classifications:
        {data}

        Please give a short explanation for your analysis and the put out the adjusted prompt like this:
        "Adjusted prompt: ..."
        [/INST]"""

        # Set up the PromptTemplate object
        self.adjust_examples_prompt = PromptTemplate(template=self.adjust_examples_template, input_variables=["data"])

    def analyze(self, below_threshold, above_threshold, within_range, previous_prompt):
        """
        Analyze the generated data classified based on thresholds and produce a report.

        Parameters:
        - within_threshold: List of dictionaries where nearest neighbor distances are within normal range.
        - below_threshold: List of dictionaries where nearest neighbor distances are below the lower threshold (too close).
        - above_threshold: List of dictionaries where nearest neighbor distances are above the upper threshold (too far).

        Returns:
        - A report generated by the model.
        """

        # Format the data for the analysis prompt, labeling based on thresholds
        data_str = ""

        # Add the data points classified as "too close"
        if below_threshold:
            data_str += "\n### Data Points Too Close To Others ###\n"
            data_str += "\n".join([f"Input: {item['text'][0]}\nOutput: {item['text'][1]}"
                                   for item in below_threshold])

        # Add the data points classified as "too far"
        if above_threshold:
            data_str += "\n### Data Points Too Far From All ###\n"
            data_str += "\n".join([f"Input: {item['text'][0]}\nOutput: {item['text'][1]}"
                                   for item in above_threshold])

        # Add the data points classified as "in range"
        if within_range:
            data_str += "\n### Data Points Just Right ###\n"
            data_str += "\n".join(
                [f"Input: {item['text'][0]}\nOutput: {item['text'][1]}"
                 for item in within_range])

        # Create an LLMChain with the model and the prompt
        llm_chain = LLMChain(prompt=self.adjust_examples_prompt, llm=self.llm)

        # Generate the report using the formatted data
        report = llm_chain.run({"prompt": previous_prompt, "data": data_str})

        return report
